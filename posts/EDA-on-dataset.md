![cover](https://www.guvi.in/blog/wp-content/uploads/2024/08/2-2.webp)
---
date: 2026-01-26
---
# Applying EDA to Feature Selection on a Real-World Insurance Dataset

Today, I applied the complete **EDA → Data Cleaning → Data Preprocessing → Feature Engineering → Feature Selection** workflow on a real-world **insurance dataset**.

[Project Source Code](https://github.com/surajsingh241205/Data-Science-Minor-And-Major-Projects/tree/main/insurance%20EDA)

This hands-on practice helped me clearly understand how raw, messy data is transformed step by step into a format that can be fed into a machine learning model.

More importantly, it showed me *why* each step exists — not just *how* to do it.

---

## What I Worked On

![](https://www.goanobserver.in/wp-content/uploads/2024/04/man-in-front-of-computer-monitor-flat-illustraiton-work-from-home-concept-free-vector.jpg)

I took an insurance people dataset and applied the full data preparation pipeline:

- Exploratory Data Analysis (EDA)
- Data Cleaning
- Data Preprocessing
- Feature Engineering
- Feature Selection

The goal was not to build a model quickly, but to **understand how real-world data behaves** and how decisions are made before modeling.

---

## Key Learnings from Exploratory Data Analysis (EDA)

![](https://thumbs.dreamstime.com/b/open-book-question-mark-key-learning-vector-design-generative-ai-conceptual-illustration-symbolizing-414275381.jpg)

EDA helped me understand:
- What each feature represents
- The distribution of numerical variables
- The behavior of categorical features
- Missing values and their impact
- Relationships between features
- How the target variable behaves

EDA made one thing very clear:

> You cannot clean, preprocess, or engineer features properly if you don’t understand the data first.

---

## Data Cleaning: Fixing What’s Wrong

Based on insights from EDA, I performed data cleaning steps such as:
- Handling missing values using appropriate strategies
- Removing duplicate records
- Fixing incorrect data types
- Handling inconsistent categorical values
- Detecting and handling outliers
- Identifying logical and domain-related errors

This phase reinforced an important idea:

> **EDA tells you what’s wrong. Data cleaning fixes it.**

---

## Data Preprocessing: Making Data Model-Ready

Once the data was clean, I focused on preprocessing to make it usable for machine learning models.

This included:
- Encoding categorical variables
- Feature transformation where required
- Feature scaling

I learned that preprocessing is not about fixing mistakes, but about **transforming valid data into a usable format**.

---

## Feature Engineering & Feature Selection

I also applied basic feature engineering and feature selection concepts:
- Creating meaningful features from existing ones
- Removing redundant or low-importance features
- Using feature selection techniques to reduce noise

This step highlighted how much **model performance depends on data representation**, not just algorithms.

---

## The Biggest Realization

![](https://img.freepik.com/free-vector/think-out-box-concept-open-your-brain-look-new-ideas-that-will-drive-your-business-work-creativity-help-see-business-opportunity-vision-idea-discover-new-solution_1150-55436.jpg?semt=ais_hybrid&w=740&q=80)

Working on a real-world dataset gave me a clear picture of how messy and imperfect real data is.

I realized that:
- Real-world datasets are rarely clean
- Decisions during EDA affect everything that comes after
- Data preparation takes more time than modeling
- Understanding the data deeply is more valuable than rushing to build models

I also encountered **some confusions in a few concepts**, which is expected at this stage. Instead of ignoring them, I plan to dig deeper and clear those gaps through further practice and study.

---

## Conclusion

This exercise helped me connect theory with practice and understand the complete data preparation pipeline in a realistic way.

It reinforced the idea that:
- Good machine learning starts with good data understanding
- Strong fundamentals matter more than speed
- Confusion is part of the learning process — clarity comes with practice

---

### What’s Next?

I’ll continue practicing on more real-world datasets and gradually move toward modeling once my data preparation foundation is strong.

For now, the focus remains on **learning correctly, not quickly**.

[Learn More On EDA](https://www.analyticsvidhya.com/blog/2021/05/exploratory-data-analysis-eda-a-step-by-step-guide/)

---

![Quote](https://datasemantics.co/wp-content/uploads/2019/06/Quote-1.jpg)